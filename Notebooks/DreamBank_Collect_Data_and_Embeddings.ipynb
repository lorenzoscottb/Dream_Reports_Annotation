{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92dd8fa2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Nov 11 09:12:32 2022       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 515.43.04    Driver Version: 515.43.04    CUDA Version: 11.7     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:03:00.0 Off |                  N/A |\r\n",
      "| 30%   34C    P0   106W / 350W |      0MiB / 24576MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   1  NVIDIA GeForce ...  Off  | 00000000:04:00.0 Off |                  N/A |\r\n",
      "| 30%   32C    P0   110W / 350W |      0MiB / 24576MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   2  NVIDIA GeForce ...  Off  | 00000000:43:00.0 Off |                  N/A |\r\n",
      "| 30%   33C    P0   104W / 350W |      0MiB / 24576MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   3  NVIDIA GeForce ...  Off  | 00000000:44:00.0 Off |                  N/A |\r\n",
      "| 30%   31C    P0   101W / 350W |      0MiB / 24576MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   4  NVIDIA GeForce ...  Off  | 00000000:87:00.0 Off |                  N/A |\r\n",
      "| 30%   18C    P8    13W / 350W |  18109MiB / 24576MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   5  NVIDIA GeForce ...  Off  | 00000000:88:00.0 Off |                  N/A |\r\n",
      "| 30%   30C    P0   107W / 350W |      0MiB / 24576MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   6  NVIDIA GeForce ...  Off  | 00000000:C3:00.0 Off |                  N/A |\r\n",
      "| 30%   30C    P0    99W / 350W |      0MiB / 24576MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   7  NVIDIA GeForce ...  Off  | 00000000:C4:00.0 Off |                  N/A |\r\n",
      "| 30%   29C    P0   110W / 350W |      0MiB / 24576MiB |      3%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    4   N/A  N/A   1083501      C   ...3/envs/cedr/bin/python3.9    18107MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "! nvidia-smi # bash command to controll the status of GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82ba9aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, random, xmltodict, json\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "cuda_device = 5 # which GPU to use\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= str(cuda_device) # set which GPU device are visible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "palestinian-clear",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Basic\" py library\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import spearmanr\n",
    "from sklearn.model_selection import train_test_split \n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# visualisation\n",
    "from tqdm import tqdm  # generats progress bar to controll steps\n",
    "\n",
    "# ML py\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "import torch # Pytorch, Meta's library for ML\n",
    "import torch.nn as nn # Pt module for neural networks \n",
    "\n",
    "import transformers # HuggingFace library to use pretrained models\n",
    "from transformers import BertTokenizer, BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bdaa463",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed: int):\n",
    "    \"\"\"Helper function for reproducible behavior to set the seed in ``random``, \n",
    "        ``numpy``, ``torch`` and/or ``tf`` (if installed).\n",
    "\n",
    "    Args:\n",
    "        seed (:obj:`int`): The seed to set.\n",
    "    \"\"\"\n",
    "    from transformers.file_utils import is_tf_available, is_torch_available, is_torch_tpu_available\n",
    "    \n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    if is_torch_available():\n",
    "        torch.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        # ^^ safe to call this function even if cuda is not available\n",
    "    if is_tf_available():\n",
    "        import tensorflow as tf\n",
    "\n",
    "        tf.random.set_seed(seed)\n",
    "        \n",
    "def get_encoding(sq, tokenizer, model, idx=0, layer=-1, device=\"cuda\", truncate=False):\n",
    "    \"\"\"\"\"\n",
    "    given a sequence, model (and tokenizer) extract the encoding for the sequnce\n",
    "    idx 0 --> CLS\n",
    "    idx 1 --> token 1\n",
    "    idx 2 --> token 2\n",
    "    \"\"\"\n",
    "    inputs = tokenizer(sq, truncation=truncate, return_tensors='pt')\n",
    "    inputs.to(device)\n",
    "    outputs = model(**inputs, output_hidden_states=True)\n",
    "    last_hidden_states = outputs.hidden_states[layer]\n",
    "    CLS = last_hidden_states[0,idx,:] # CLS = [0,0,:], \n",
    "    CLS = CLS.to(\"cpu\").detach().numpy()\n",
    "    return CLS\n",
    "\n",
    "def get_norm_reports():\n",
    "    fl_lst = []\n",
    "    for gender in [\"m\", \"f\"]:\n",
    "        for fl in os.listdir(\"norms-{}\".format(gender)):\n",
    "            fl_name = \"{}/norms-{}/{}\".format(os.getcwd(),gender, fl)\n",
    "            lcl_fl = open(fl_name, \"r\").read()\n",
    "            fl_lst.append([lcl_fl, gender])\n",
    "    df = pd.DataFrame(fl_lst, columns=[\"Report\", \"Gender\"]) \n",
    "    \n",
    "    return df\n",
    "\n",
    "def underscore_label(ch_sq):\n",
    "    splt_sq = list(ch_sq)\n",
    "    n = splt_sq[0]\n",
    "    lbl = \"\".join(splt_sq[1:])\n",
    "    return \"_\".join([n, lbl])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd0722f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  set the random seed \n",
    "seed = 31\n",
    "set_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "favorite-prize",
   "metadata": {},
   "source": [
    "# Table of Content\n",
    "\n",
    "click on the titles to reach the described sections\n",
    "\n",
    "---------\n",
    "[Loading and Scraping Data](#intro)\n",
    "\n",
    "[Dreams Encoding](#encoding)\n",
    "\n",
    "[Get PCA /. t-SNE](#dimred)\n",
    "\n",
    "The notebook limits to data collection. First, data (i.e., the general and dreamer-based emtions) is scraped from the original .xlm file, converted and saved as `.csv` file. Afterwards,  A `BERT-large-cased` model is used to collect the encodings of each report, that re then stored as a `numpy` array. Lastly, encodings are used to obtain the reduction of the reports' space according to PCA and t-SNE methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "weird-illness",
   "metadata": {},
   "source": [
    "## Loading and scraping data<a id='intro'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f4fff91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Get Dremer-Bssed emotion from XLM ####\n",
    "def get_Emotions(file=\"coded_dreams.xml\"):\n",
    "    tree = ET.parse(file)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    lst = []\n",
    "\n",
    "    for collection in tqdm(root):\n",
    "\n",
    "        gender = collection.findtext(\"sex\")\n",
    "        age    = collection.findtext(\"age\")\n",
    "        typ    = collection.findtext(\"type\")\n",
    "        name   = collection.findtext(\"name\")\n",
    "        idd    = collection.findtext(\"id\")\n",
    "        time   = collection.findtext(\"time\")\n",
    "\n",
    "        for dream in collection.findall(\"dream\"):\n",
    "            date   = dream.findtext(\"date\")\n",
    "            date   =  date if date != None else \"Missing\"\n",
    "            number = dream.findtext(\"number\")\n",
    "            report = dream.findtext(\"report\")\n",
    "\n",
    "            try:\n",
    "                n_wrds = len(word_tokenize(report))\n",
    "            except:\n",
    "                n_wrds = 0\n",
    "\n",
    "            all_emotions_labels     = []\n",
    "            dreamer_emotions_labels = []\n",
    "\n",
    "    #         for ch in dream.find(\"codings\").findall(\"char\"): # collects Characters deprecated\n",
    "    #             lcl_labels.append(underscore_label(ch.text))\n",
    "\n",
    "            for emot in dream.find(\"codings\").findall(\"emot\"): # collects emot(ions) of D(reamer)\n",
    "                E   = emot[0].text\n",
    "                Chr = emot[1].text\n",
    "                all_emotions_labels.append(E)\n",
    "                if Chr == \"D\": # store if charcater of the omotion is the D(reamer)\n",
    "                    dreamer_emotions_labels.append(E)\n",
    "                    \n",
    "            all_emotions_labels     = \"Missing\" if all_emotions_labels == [] else \"_\".join(all_emotions_labels)\n",
    "            dreamer_emotions_labels = \"Missing\" if dreamer_emotions_labels == [] else \"_\".join(dreamer_emotions_labels)\n",
    "\n",
    "            lst.append(\n",
    "                    [\n",
    "                    gender, age, typ, name, idd, time, \n",
    "                    date, number, report, n_wrds, \n",
    "                    all_emotions_labels, dreamer_emotions_labels\n",
    "                    ]\n",
    "            )\n",
    "            \n",
    "    return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f854fab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 7/7 [00:01<00:00,  4.84it/s]\n"
     ]
    }
   ],
   "source": [
    "dream_records_lst = get_Emotions()\n",
    "dream_records = pd.DataFrame(\n",
    "                    dream_records_lst, \n",
    "                    columns=[\n",
    "                            \"gender\", \"age\", \"type\", \"collection\", \"id\", \n",
    "                            \"time\", \"date\", \"number\", \"report\", \"# words\", \n",
    "                            \"All Emotions\", \"Dreamer Emotions\" \n",
    "                    ]\n",
    ")\n",
    "\n",
    "dream_records[\"# Dreamer Emotions\"] = [\n",
    "    len(e_lst.split(\"_\")) if e_lst != \"Missing\" else 0\n",
    "    for e_lst in dream_records[\"Dreamer Emotions\"]\n",
    "]\n",
    "\n",
    "dream_records[\"# General Emotions\"] = [\n",
    "    len(e_lst.split(\"_\")) if e_lst != \"Missing\" else 0\n",
    "    for e_lst in dream_records[\"All Emotions\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a28bf576",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to .csv\n",
    "dream_records.to_csv(\"Reports_with_Dreamer_and_General_Emotions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f192432",
   "metadata": {},
   "source": [
    "Get a general idea of the final file!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "98529ba5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>type</th>\n",
       "      <th>collection</th>\n",
       "      <th>id</th>\n",
       "      <th>time</th>\n",
       "      <th>date</th>\n",
       "      <th>number</th>\n",
       "      <th>report</th>\n",
       "      <th># words</th>\n",
       "      <th>All Emotions</th>\n",
       "      <th>Dreamer Emotions</th>\n",
       "      <th># Dreamer Emotions</th>\n",
       "      <th># General Emotions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>M</td>\n",
       "      <td>A</td>\n",
       "      <td>series</td>\n",
       "      <td>Ed: dreams of his late wife</td>\n",
       "      <td>ed</td>\n",
       "      <td>1980-2002</td>\n",
       "      <td>11/07/85</td>\n",
       "      <td>039</td>\n",
       "      <td>Mary and her sister Kathy are busy repairing a...</td>\n",
       "      <td>375</td>\n",
       "      <td>AP_HA_HA_HA_HA</td>\n",
       "      <td>AP_HA_HA</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>series</td>\n",
       "      <td>Bea 1: a high school student</td>\n",
       "      <td>bea1</td>\n",
       "      <td>2003-2005</td>\n",
       "      <td>08/17/2004 (age 15)</td>\n",
       "      <td>180</td>\n",
       "      <td>I dreamed that the girls from my Spain program...</td>\n",
       "      <td>242</td>\n",
       "      <td>SD_AN</td>\n",
       "      <td>Missing</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905</th>\n",
       "      <td>F</td>\n",
       "      <td>Y</td>\n",
       "      <td>set</td>\n",
       "      <td>Hall/VdC Norms: Female</td>\n",
       "      <td>norms-f</td>\n",
       "      <td>1940s-1950s</td>\n",
       "      <td>Missing</td>\n",
       "      <td>0042</td>\n",
       "      <td>I dreamt that a friend of mine who graduated l...</td>\n",
       "      <td>146</td>\n",
       "      <td>HA</td>\n",
       "      <td>HA</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    gender age    type                    collection       id         time  \\\n",
       "459      M   A  series   Ed: dreams of his late wife       ed    1980-2002   \n",
       "380      F   T  series  Bea 1: a high school student     bea1    2003-2005   \n",
       "905      F   Y     set        Hall/VdC Norms: Female  norms-f  1940s-1950s   \n",
       "\n",
       "                    date number  \\\n",
       "459             11/07/85    039   \n",
       "380  08/17/2004 (age 15)    180   \n",
       "905              Missing   0042   \n",
       "\n",
       "                                                report  # words  \\\n",
       "459  Mary and her sister Kathy are busy repairing a...      375   \n",
       "380  I dreamed that the girls from my Spain program...      242   \n",
       "905  I dreamt that a friend of mine who graduated l...      146   \n",
       "\n",
       "       All Emotions Dreamer Emotions  # Dreamer Emotions  # General Emotions  \n",
       "459  AP_HA_HA_HA_HA         AP_HA_HA                   3                   5  \n",
       "380           SD_AN          Missing                   0                   2  \n",
       "905              HA               HA                   1                   1  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dream_records = dream_records[dream_records[\"# words\"] != 0]\n",
    "dream_records.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a833e22",
   "metadata": {},
   "source": [
    "## Dreams Encoding<a id='encoding'></a>\n",
    "\n",
    "Collect the encodings (i.e., the vectors, for each report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d21d99f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1845.000000\n",
       "mean      144.784282\n",
       "std        78.240335\n",
       "min         8.000000\n",
       "25%        91.000000\n",
       "50%       129.000000\n",
       "75%       178.000000\n",
       "max       610.000000\n",
       "Name: # words, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # We need to identify the seq. lenght, so to not luse items with paddings\n",
    "dream_records[\"# words\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e99fd1de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# https://huggingface.co/bert-base-multilingual-cased\n",
    "# we use BERT as no transfer is needed \n",
    "model_name = \"bert-large-cased\"\n",
    "# max sequence length for each document/sentence sample\n",
    "ml = 512\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model     = BertModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c40f0dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ditch the 9 misaing items\n",
    "dream_records = dream_records[dream_records[\"# words\"] != 0].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "17b4f091",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 1845/1845 [00:02<00:00, 659.73it/s]\n"
     ]
    }
   ],
   "source": [
    "# we need to know which seq have more than 512 tokens and remove them\n",
    "T_encoding = [tokenizer(sq, truncation=True) for sq in tqdm(dream_records[\"report\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3497f84f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 1845/1845 [04:15<00:00,  7.21it/s]\n"
     ]
    }
   ],
   "source": [
    "# # Collect the embeddings of each report according to the model\n",
    "T_encoding = [get_encoding(sq, tokenizer, model, device=\"cpu\", truncate=True) \n",
    "              for sq in tqdm(dream_records[\"report\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "19099174",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1845, 1024)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T_encoding = np.array(T_encoding)\n",
    "np.array(T_encoding).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0bfd6d",
   "metadata": {},
   "source": [
    "Save the encodings (i.e., BERT's vectors) as numpy array. This option is preferable to store the encodings to the DataFrame as Pandas will convert them into strigs, making it diffucult in future uplading to use them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0a750104",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('BERT-Large-Cased_dream_records.npy', 'wb') as f:\n",
    "    np.save(f, T_encoding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7cda06f",
   "metadata": {},
   "source": [
    "## Get PCA / t-SNE<a id='dimred'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "19b3d054",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA reduction\n",
    "pca     = PCA(n_components=2)\n",
    "TKN_PCA = pca.fit_transform(T_encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ff2ade92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/galene1/lb540/miniconda/envs/main_39/lib/python3.9/site-packages/sklearn/manifold/_t_sne.py:790: FutureWarning: The default learning rate in TSNE will change from 200.0 to 'auto' in 1.2.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#t-SNE reduction\n",
    "TKN_TSNE = TSNE(\n",
    "            n_components=2,\n",
    "            init='random'\n",
    ").fit_transform(T_encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4d67735f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store in DF\n",
    "dream_records[\"TSNE_x\"], dream_records[\"TSNE_y\"] = zip(*TKN_TSNE)\n",
    "dream_records[\"PCA_x\"], dream_records[\"PCA_y\"]   = zip(*TKN_PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "27331acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data so far collected as .csv\n",
    "dream_records.to_csv(\n",
    "    \"Reports_with_Dreamer_and_General_Emotions_PCAxy_tSNExy.csv\",\n",
    "    index=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ed2999",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
