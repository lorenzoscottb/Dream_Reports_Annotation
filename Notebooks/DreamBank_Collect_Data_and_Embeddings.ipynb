{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92dd8fa2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Sep 30 15:16:32 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 515.43.04    Driver Version: 515.43.04    CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:03:00.0 Off |                  N/A |\n",
      "| 30%   40C    P0   107W / 350W |      0MiB / 24576MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA GeForce ...  Off  | 00000000:04:00.0 Off |                  N/A |\n",
      "| 30%   37C    P0   112W / 350W |      0MiB / 24576MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA GeForce ...  Off  | 00000000:43:00.0 Off |                  N/A |\n",
      "| 30%   38C    P0   106W / 350W |      0MiB / 24576MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  NVIDIA GeForce ...  Off  | 00000000:44:00.0 Off |                  N/A |\n",
      "| 30%   36C    P0   102W / 350W |      0MiB / 24576MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  NVIDIA GeForce ...  Off  | 00000000:87:00.0 Off |                  N/A |\n",
      "| 30%   37C    P0   120W / 350W |      0MiB / 24576MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  NVIDIA GeForce ...  Off  | 00000000:88:00.0 Off |                  N/A |\n",
      "| 30%   22C    P8     5W / 350W |  12579MiB / 24576MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   6  NVIDIA GeForce ...  Off  | 00000000:C3:00.0 Off |                  N/A |\n",
      "| 30%   35C    P0   100W / 350W |      0MiB / 24576MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   7  NVIDIA GeForce ...  Off  | 00000000:C4:00.0 Off |                  N/A |\n",
      "| 30%   35C    P0   111W / 350W |      0MiB / 24576MiB |      3%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    5   N/A  N/A   1397311      C   .../envs/token_18/bin/python    12577MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "! nvidia-smi # bash command to controll the status of GPUs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82ba9aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, random, xmltodict, json\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "cuda_device = 6 # which GPU to use\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= str(cuda_device) # set which GPU device are visible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "palestinian-clear",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Basic\" py library\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import spearmanr\n",
    "from sklearn.model_selection import train_test_split \n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Stats \n",
    "from mlxtend.evaluate import permutation_test\n",
    "\n",
    "# visualisation\n",
    "from matplotlib import pyplot as plt # basic visualisation in py\n",
    "import seaborn as sns # great to interact with dataframes\n",
    "import plotly.express as px # powerfull for interactive figures\n",
    "from tqdm import tqdm  # generats progress bar to controll steps\n",
    "\n",
    "# ML py\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "import torch # Pytorch, Meta's library for ML\n",
    "import torch.nn as nn # Pt module for neural networks \n",
    "\n",
    "import transformers # HuggingFace library to use pretrained models\n",
    "from transformers import BertTokenizer, BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7bdaa463",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed: int):\n",
    "    \"\"\"Helper function for reproducible behavior to set the seed in ``random``, \n",
    "        ``numpy``, ``torch`` and/or ``tf`` (if installed).\n",
    "\n",
    "    Args:\n",
    "        seed (:obj:`int`): The seed to set.\n",
    "    \"\"\"\n",
    "    from transformers.file_utils import is_tf_available, is_torch_available, is_torch_tpu_available\n",
    "    \n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    if is_torch_available():\n",
    "        torch.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        # ^^ safe to call this function even if cuda is not available\n",
    "    if is_tf_available():\n",
    "        import tensorflow as tf\n",
    "\n",
    "        tf.random.set_seed(seed)\n",
    "        \n",
    "def get_encoding(sq, tokenizer, model, idx=0, layer=-1, device=\"cuda\", truncate=False):\n",
    "    \"\"\"\"\"\n",
    "    given a sequence, model (and tokenizer) extract the encoding for the sequnce\n",
    "    idx 0 --> CLS\n",
    "    idx 1 --> token 1\n",
    "    idx 2 --> token 2\n",
    "    \"\"\"\n",
    "    inputs = tokenizer(sq, truncation=truncate, return_tensors='pt')\n",
    "    inputs.to(device)\n",
    "    outputs = model(**inputs, output_hidden_states=True)\n",
    "    last_hidden_states = outputs.hidden_states[layer]\n",
    "    CLS = last_hidden_states[0,idx,:] # CLS = [0,0,:], \n",
    "    CLS = CLS.to(\"cpu\").detach().numpy()\n",
    "    return CLS\n",
    "\n",
    "def get_norm_reports():\n",
    "    fl_lst = []\n",
    "    for gender in [\"m\", \"f\"]:\n",
    "        for fl in os.listdir(\"norms-{}\".format(gender)):\n",
    "            fl_name = \"{}/norms-{}/{}\".format(os.getcwd(),gender, fl)\n",
    "            lcl_fl = open(fl_name, \"r\").read()\n",
    "            fl_lst.append([lcl_fl, gender])\n",
    "    df = pd.DataFrame(fl_lst, columns=[\"Report\", \"Gender\"]) \n",
    "    \n",
    "    return df\n",
    "\n",
    "def underscore_label(ch_sq):\n",
    "    splt_sq = list(ch_sq)\n",
    "    n = splt_sq[0]\n",
    "    lbl = \"\".join(splt_sq[1:])\n",
    "    return \"_\".join([n, lbl])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd0722f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set visual style of Seabonr\n",
    "sns.set(\"talk\")\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "#  set the random seed \n",
    "seed = 31\n",
    "set_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "favorite-prize",
   "metadata": {},
   "source": [
    "# Table of Content\n",
    "\n",
    "click on the titles to reach the described sections\n",
    "\n",
    "---------\n",
    "[Loading and Scraping Data](#intro)\n",
    "\n",
    "[Dreams Encoding](#encoding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "weird-illness",
   "metadata": {},
   "source": [
    "## Loading and scraping data<a id='intro'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f4fff91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 7/7 [00:01<00:00,  4.82it/s]\n"
     ]
    }
   ],
   "source": [
    "#### Deprecated/Used code to convert XLM to csv ####\n",
    "tree = ET.parse('coded_dreams.xml')\n",
    "root = tree.getroot()\n",
    "\n",
    "lst = []\n",
    "\n",
    "for collection in tqdm(root):\n",
    "    \n",
    "    gender = collection.findtext(\"sex\")\n",
    "    age    = collection.findtext(\"age\")\n",
    "    typ    = collection.findtext(\"type\")\n",
    "    name   = collection.findtext(\"name\")\n",
    "    idd    = collection.findtext(\"id\")\n",
    "    time   = collection.findtext(\"time\")\n",
    "    \n",
    "    for dream in collection.findall(\"dream\"):\n",
    "        date   = dream.findtext(\"date\")\n",
    "        date   =  date if date != None else \"Missing\"\n",
    "        number = dream.findtext(\"number\")\n",
    "        report = dream.findtext(\"report\")\n",
    "        \n",
    "        try:\n",
    "            n_wrds = len(word_tokenize(report))\n",
    "        except:\n",
    "            n_wrds = 0\n",
    "            \n",
    "        lcl_labels = []\n",
    "\n",
    "#         for ch in dream.find(\"codings\").findall(\"char\"): # collects Characters deprecated\n",
    "#             lcl_labels.append(underscore_label(ch.text))\n",
    "\n",
    "        for emot in dream.find(\"codings\").findall(\"emot\"): # collects emot(ions) of D(reamer)\n",
    "            E   = emot[0].text\n",
    "            Chr = emot[1].text\n",
    "            if Chr == \"D\": # store if charcater of the omotion is the D(reamer)\n",
    "                lcl_labels.append(E)\n",
    "        \n",
    "        \n",
    "        lcl_labels = \"Missing\" if lcl_labels == [] else \"_\".join(lcl_labels)\n",
    "        \n",
    "        lst.append(\n",
    "                [\n",
    "                gender, age, typ, name, idd, time, \n",
    "                date, number, report, n_wrds, lcl_labels\n",
    "                ]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f854fab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dream_records = pd.DataFrame(\n",
    "                    lst, \n",
    "                    columns=[\n",
    "                            \"gender\", \"age\", \"type\", \"collection\", \"id\", \n",
    "                            \"time\", \"date\", \"number\", \"report\", \"# words\", \"Emotions\"\n",
    "                    ]\n",
    ")\n",
    "\n",
    "dream_records[\"# Emotions\"] = [\n",
    "    len(e_lst.split(\"_\")) if e_lst != \"Missing\" else 0\n",
    "    for e_lst in dream_records[\"Emotions\"]\n",
    "]\n",
    "\n",
    "# Save to .csv\n",
    "# dream_records.to_csv(\"Reports_with_Dreamer_Emotions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98529ba5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>type</th>\n",
       "      <th>collection</th>\n",
       "      <th>id</th>\n",
       "      <th>time</th>\n",
       "      <th>date</th>\n",
       "      <th>number</th>\n",
       "      <th>report</th>\n",
       "      <th># words</th>\n",
       "      <th>Emotions</th>\n",
       "      <th># Emotions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1511</th>\n",
       "      <td>M</td>\n",
       "      <td>Y</td>\n",
       "      <td>set</td>\n",
       "      <td>Hall/VdC Norms: Male</td>\n",
       "      <td>norms-m</td>\n",
       "      <td>1940s-1950s</td>\n",
       "      <td>Missing</td>\n",
       "      <td>0157</td>\n",
       "      <td>I walked out of the washroom at our country cl...</td>\n",
       "      <td>92</td>\n",
       "      <td>AP_SD</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>933</th>\n",
       "      <td>F</td>\n",
       "      <td>Y</td>\n",
       "      <td>set</td>\n",
       "      <td>Hall/VdC Norms: Female</td>\n",
       "      <td>norms-f</td>\n",
       "      <td>1940s-1950s</td>\n",
       "      <td>Missing</td>\n",
       "      <td>0070</td>\n",
       "      <td>I had to take an exam in the psych lab. When I...</td>\n",
       "      <td>161</td>\n",
       "      <td>Missing</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1830</th>\n",
       "      <td>M</td>\n",
       "      <td>Y</td>\n",
       "      <td>set</td>\n",
       "      <td>Hall/VdC Norms: Male</td>\n",
       "      <td>norms-m</td>\n",
       "      <td>1940s-1950s</td>\n",
       "      <td>Missing</td>\n",
       "      <td>0476</td>\n",
       "      <td>In this dream I received a letter from my girl...</td>\n",
       "      <td>136</td>\n",
       "      <td>AN_SD</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     gender age type              collection       id         time     date  \\\n",
       "1511      M   Y  set    Hall/VdC Norms: Male  norms-m  1940s-1950s  Missing   \n",
       "933       F   Y  set  Hall/VdC Norms: Female  norms-f  1940s-1950s  Missing   \n",
       "1830      M   Y  set    Hall/VdC Norms: Male  norms-m  1940s-1950s  Missing   \n",
       "\n",
       "     number                                             report  # words  \\\n",
       "1511   0157  I walked out of the washroom at our country cl...       92   \n",
       "933    0070  I had to take an exam in the psych lab. When I...      161   \n",
       "1830   0476  In this dream I received a letter from my girl...      136   \n",
       "\n",
       "     Emotions  # Emotions  \n",
       "1511    AP_SD           2  \n",
       "933   Missing           0  \n",
       "1830    AN_SD           2  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dream_records = dream_records[dream_records[\"# words\"] != 0]\n",
    "dream_records.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99c6f558",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1855"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dream_records)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a833e22",
   "metadata": {},
   "source": [
    "## Dreams Encoding<a id='encoding'></a>\n",
    "\n",
    "Collect the encodings (i.e., the vectors, for each report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d21d99f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1845.000000\n",
       "mean      144.784282\n",
       "std        78.240335\n",
       "min         8.000000\n",
       "25%        91.000000\n",
       "50%       129.000000\n",
       "75%       178.000000\n",
       "max       610.000000\n",
       "Name: # words, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # We need to identify the seq. lenght, so to not luse items with paddings\n",
    "dream_records[\"# words\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e99fd1de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-cased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# https://huggingface.co/bert-base-multilingual-cased\n",
    "# we use BERT as no transfer is needed \n",
    "model_name = \"bert-large-cased\"\n",
    "# max sequence length for each document/sentence sample\n",
    "ml = 512\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model     = BertModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c40f0dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ditch the 9 misaing items\n",
    "dream_records = dream_records[dream_records[\"# words\"] != 0].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "17b4f091",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 1845/1845 [00:02<00:00, 681.08it/s]\n"
     ]
    }
   ],
   "source": [
    "# we need to know which seq have more than 512 tokens and remove them\n",
    "T_encoding = [tokenizer(sq, truncation=True) for sq in tqdm(dream_records[\"report\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3497f84f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 1845/1845 [05:28<00:00,  5.61it/s]\n"
     ]
    }
   ],
   "source": [
    "# # Collect the embeddings of each report according to the model\n",
    "T_encoding = [get_encoding(sq, tokenizer, model, device=\"cpu\", truncate=True) \n",
    "              for sq in tqdm(dream_records[\"report\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "19099174",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1845, 1024)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T_encoding = np.array(T_encoding)\n",
    "np.array(T_encoding).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0a750104",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('BERT-Large-Cased_dream_records.npy', 'wb') as f:\n",
    "#     np.save(f, T_encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "19b3d054",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA reduction\n",
    "pca     = PCA(n_components=2)\n",
    "TKN_PCA = pca.fit_transform(T_encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ff2ade92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/galene1/lb540/miniconda/envs/main_39/lib/python3.9/site-packages/sklearn/manifold/_t_sne.py:810: FutureWarning: The default learning rate in TSNE will change from 200.0 to 'auto' in 1.2.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#t-SNE reduction\n",
    "TKN_TSNE = TSNE(\n",
    "            n_components=2,\n",
    "            init='random'\n",
    ").fit_transform(T_encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4d67735f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store in DF\n",
    "dream_records[\"TSNE_x\"], dream_records[\"TSNE_y\"] = zip(*TKN_TSNE)\n",
    "dream_records[\"PCA_x\"], dream_records[\"PCA_y\"]   = zip(*TKN_PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "27331acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data so far collected as .csv\n",
    "dream_records.to_csv(\n",
    "    \"Reports_DreamerEmotions_PCAxy_tSNExy.csv\",\n",
    "    index=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ed2999",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c025988",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21808e42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ef6d3ab1",
   "metadata": {},
   "source": [
    "# Deprecated Code \n",
    "Mostly setting nwe dataframe with old choordinats and custers for consisntency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "32039c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# old_reports = pd.read_csv(\"Dreams_with_embeddings.csv\")\n",
    "# old_reports.columns\n",
    "\n",
    "# for clmn_nm in ['Kmean Cluster C', 'Kmean Cluster G', 'SA label', 'SA score', 'Emotions']:\n",
    "#     if clmn_nm == 'SA label':\n",
    "#         lcl_nm = \"2Way_SA_lable\"\n",
    "#     elif clmn_nm == 'SA score':\n",
    "#         lcl_nm = \"2Way_SA_score\"\n",
    "#     elif clmn_nm == 'Emotions':\n",
    "#         lcl_nm = \"5Way_SA_dict\"\n",
    "#     else:\n",
    "#         lcl_nm = clmn_nm\n",
    "#     dream_records[lcl_nm] = old_reports[clmn_nm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0774b4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dream_records.to_csv(\n",
    "#     \"Reports_DreamerEmotions_PCACho_tsneCho_KMCluster2_KMCluster6_2WSA_5WSA.csv\",\n",
    "#     index=False,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a9d3436",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForMaskedLM, AutoTokenizer\n",
    "import pandas as pd \n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "751f9e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "dream_records = pd.read_csv(\n",
    "    \"Reports_DreamerEmotions_PCACho_tsneCho_KMCluster2_KMCluster6_2WSA_6WSA.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c049dd13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model_name = \"bert-large-cased\"\n",
    "\n",
    "model     = AutoModelForMaskedLM.from_pretrained(model_name).to(\"cuda\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da378c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                  | 0/1845 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "ppl_scores = []\n",
    "for report in tqdm(dream_records[\"report\"].to_list()):\n",
    "    \n",
    "    tensor_input = tokenizer.encode(report, return_tensors='pt')\n",
    "    repeat_input = tensor_input.repeat(tensor_input.size(-1)-2, 1)\n",
    "    mask         = torch.ones(tensor_input.size(-1) - 1).diag(1)[:-2]\n",
    "    masked_input = repeat_input.masked_fill(mask == 1, tokenizer.mask_token_id)\n",
    "    labels       = repeat_input.masked_fill(masked_input != tokenizer.mask_token_id, -100)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        masked_input, labels = masked_input.to(\"cuda\"), labels.to(\"cuda\")\n",
    "        loss = model(masked_input, labels=labels).loss\n",
    "        loss = np.exp(loss.item())\n",
    "        ppl_scores.append(loss)\n",
    "        \n",
    "        loss, masked_input, labels = loss.to(\"cpu\"), masked_input.to(\"cpu\"), labels.to(\"cpu\")\n",
    "        del loss, masked_input, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc61d9ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
