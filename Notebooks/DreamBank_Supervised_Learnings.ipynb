{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92dd8fa2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Oct  3 17:31:41 2022       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 515.43.04    Driver Version: 515.43.04    CUDA Version: 11.7     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:03:00.0 Off |                  N/A |\r\n",
      "| 31%   44C    P0   109W / 350W |      0MiB / 24576MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   1  NVIDIA GeForce ...  Off  | 00000000:04:00.0 Off |                  N/A |\r\n",
      "| 30%   41C    P0   113W / 350W |      0MiB / 24576MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   2  NVIDIA GeForce ...  Off  | 00000000:43:00.0 Off |                  N/A |\r\n",
      "| 30%   42C    P0   107W / 350W |      0MiB / 24576MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   3  NVIDIA GeForce ...  Off  | 00000000:44:00.0 Off |                  N/A |\r\n",
      "| 30%   41C    P0   102W / 350W |      0MiB / 24576MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   4  NVIDIA GeForce ...  Off  | 00000000:87:00.0 Off |                  N/A |\r\n",
      "| 30%   44C    P0   123W / 350W |      0MiB / 24576MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   5  NVIDIA GeForce ...  Off  | 00000000:88:00.0 Off |                  N/A |\r\n",
      "| 30%   40C    P0   113W / 350W |      0MiB / 24576MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   6  NVIDIA GeForce ...  Off  | 00000000:C3:00.0 Off |                  N/A |\r\n",
      "| 30%   41C    P0   103W / 350W |      0MiB / 24576MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   7  NVIDIA GeForce ...  Off  | 00000000:C4:00.0 Off |                  N/A |\r\n",
      "| 30%   41C    P0   114W / 350W |      0MiB / 24576MiB |      3%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|  No running processes found                                                 |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "! nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82ba9aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, random\n",
    "\n",
    "cuda_device = 3\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= str(cuda_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "palestinian-clear",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1458056/3906619096.py:19: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n",
      "  metric = load_metric('accuracy')\n"
     ]
    }
   ],
   "source": [
    "# \"Basic\" py library\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# visualisation\n",
    "from matplotlib import pyplot as plt # basic visualisation in py\n",
    "import seaborn as sns # great to interact with dataframes\n",
    "import plotly.express as px # powerfull for interactive figures\n",
    "from tqdm import tqdm  # generats progress bar to controll steps\n",
    "\n",
    "import torch # Pytorch, Meta's library for ML\n",
    "import torch.nn as nn # torch module for neural networks \n",
    "\n",
    "import transformers # HuggingFace library to use pretrained models\n",
    "from transformers import BertTokenizerFast, BertForSequenceClassification\n",
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "from datasets import load_metric\n",
    "metric = load_metric('accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bdaa463",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed: int):\n",
    "    \"\"\"Helper function for reproducible behavior to set the seed in ``random``, \n",
    "        ``numpy``, ``torch`` and/or ``tf`` (if installed).\n",
    "\n",
    "    Args:\n",
    "        seed (:obj:`int`): The seed to set.\n",
    "    \"\"\"\n",
    "    from transformers.file_utils import is_tf_available, is_torch_available, is_torch_tpu_available\n",
    "    \n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    if is_torch_available():\n",
    "        torch.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        # ^^ safe to call this function even if cuda is not available\n",
    "    if is_tf_available():\n",
    "        import tensorflow as tf\n",
    "\n",
    "        tf.random.set_seed(seed)\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd0722f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set visual style\n",
    "sns.set(\"talk\")\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "#  set the rabdom seed \n",
    "seed = 31\n",
    "set_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "favorite-prize",
   "metadata": {},
   "source": [
    "# Table of Content\n",
    "\n",
    "click on the titles to reach the described sections\n",
    "\n",
    "---------\n",
    "[Loading Data](#intro)\n",
    "\n",
    "[Tuning classification layer](#cls)\n",
    "\n",
    "[Frozen + Logit Regression](#sigmoid)\n",
    "\n",
    "[Frozen + FFN](#ffnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "weird-illness",
   "metadata": {},
   "source": [
    "## Loading data<a id='intro'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98529ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset in CSV\n",
    "dream_records = pd.read_csv(\n",
    "    \"Reports_DreamerEmotions_PCACho_tsneCho_KMCluster2_KMCluster6_2WSA_6WSA.csv\"\n",
    ")\n",
    "\n",
    "Coding_emotions = {\n",
    "    \"AN\": \"Anger\",\n",
    "    \"AP\": \"Apprehension\",\n",
    "    \"SD\": \"Sadness\",\n",
    "    \"CO\": \"Confusion\",\n",
    "    \"HA\": \"Happiness\",\n",
    "    \n",
    "    \"Missing\": \"Missing\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "195d3739",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"I was, living here in Cleveland in a fraternity house, but it was located in a downtown section. My fraternity brothers were fellows I used to know back home except one who I remember as being a fellow I know from Cleveland. I was upstairs cleaning up around. Then I came downstairs and found a lot of colored people there. Right away I noticed they had lipstick on, and this struck me as being peculiar. I couldn't help staring; once when I noticed that I was watching them, they attempted to hide their faces, some did at least. There were a bunch of dogs with them also. The dogs had fleas or something and were spreading an epidemic of disease in the neighborhood. I realized that I had to get serum to stop the epidemic. I didn't know where to get the serum. I had no transportation and went back to the fraternity house, but no one had any transportation. One fellow lent me his bicycle, so I started. I went about one block and saw a buddy of mine driving a bus, so I laid my bicycle down and asked him to take me. He said he couldn't, so I went back to get the bicycle and someone had stolen it. Finally another friend came by in a car and I got in. We started off.\",\n",
       " 'The setting of this dream was in a woods on a late summer afternoon. I was walking down a path through the trees seemingly as I recollect, with some sort of problem on my mind. As I was walking along I gradually became aware of a scantily clad girl walking a short distance ahead of me. As I was looking up at her with some degree of surprise at her attire she turned around and smiled at me and began running on ahead. I started to give chase running faster and faster but never quite catching up to her. The dream ended with this little game of run and chase with an emission. The girl in this dream is not recognizable although I remember that she had blond hair which may or may not be representative of an acquaintance.',\n",
       " \"The concert was overflowing with people. Out on the stage stepped Nelson Eddy, America's favorite baritone. I had talked to him before the concert and told him that someday I would like to sing on this very stage. Imagine my surprise when he asked me to sing several numbers on the program with him, the great Nelson Eddy.\",\n",
       " 'I was just entering a dormitory on campus to call on a young lady. As I entered, I met, to my surprise, a very good friend of mine from my hometown. He was rather angry at me and would not speak to me. Just then a young girl whom I have not seen in at least 3 or 4 years came walking down the steps. She, also, was angry at me because she said we had seen each other on campus a few times, and I had not said anything to her. I jokingly took her in my arms and was kidding her about my not having ever seen her. At that moment the alarm rang. The fellow is a very good friend of mine, while the girl in the dream was and is a rather strange acquaintance. I went to school with her, never had any associations or interests toward her. Both people are the same age as I am.',\n",
       " 'I was walking down a street in an unknown city. It might have been San Francisco, but it was not that clear. I was dressed in some sort of a uniform. It was made up of blue pants and a red cap. The brightness of the red color bothered me. I was looking for my girlfriend, although I knew that I would not find her. As I walked along a woman Marine came along and took my arm. She seemed to be a stuffed dummy, because her arm felt like cloth stuffed with sawdust. I turned to ask her if she knew where I could find my girlfriend and found that she had disappeared. I then stopped at my car, but found in its place an old green Model T Ford which was crowded with a group of my fraternity brothers. They were going to a football game at a stadium which was very close to where the car was parked. I could not recognize any of them and took it for granted that they were my friends. They gave me two tickets to the game, and then they also disappeared. I was left alone holding the two tickets and wondering where I could find a girl to take to the game.',\n",
       " \"I had a dream within a dream in which I went to sleep and had a wet dream. I woke up in my second dream and started to take off my underwear in preparation for a shower. To my surprise I found out that they weren't wet, so I went back to sleep. Then I woke up out of my first dream and found out that my underwear were wet, so I had to take them off and take a shower.\",\n",
       " \"I was riding down Hough Ave. near east 75th St. with Phil Harris, the famous star of movie and radio fame. As we stopped at the corner signal, Alice Faye, Harris' blond wife passed in front of us. Both of them smiled at each other in recognition and launched a snappy, humorous dialogue that is so characteristic of their weekly radio programs. I recalled a distinct sense of awe as I marveled at their keen wit and sense of humor.\",\n",
       " 'I looked into a tavern and saw a neighborhood girl whom I like. I ran across the street to my car, and before entering it, I looked around to be sure she was watching. I jumped into the car and stomped on the accelerator and went roaring down the street. I said to a friend who was walking down the street, \"I must be doing a hundred.\" He laughed and said, \"Oh, you\\'re only doing fifty.\" I looked at the speedometer and was surprised and rather shocked to see that he was right. I then pulled into my driveway and went into the house.',\n",
       " \"I borrowed a book from someone at the co-op whose name I believe was Bernie. Actually I'm not sure of who this Bernie was, but he seemed to be a good friend of mine, and I had a mild superior feeling toward him; that is, I had the feeling that I would always act natural when talking to him, whereas with many of the members of the co-op, I still act somewhat superficial. I was returning the book to this Bernie, and he lived at a two-family house. I rang the upstairs bell, and some male co- op members answered the door. I asked for Bernie, and they told me he lived downstairs. I went downstairs and rang the bell, and when the door opened I found that more co-op fellows were living together downstairs. I was somewhat surprised that they were all living in the same house. I returned the book. I also had the feeling that this Bernie was a small guy of slight build.\",\n",
       " 'Our hunting expedition was in deepest Africa and we were going through the dark underbrush. I was the last one in the group. All at once caught by surprise I was caught by a python snake. Struggle as I would, I could not break away from the death grip. Gradually I felt my strength leave me and I hollered to no avail. Suddenly I awoke with a bang on the dormitory door. My covers were wrapped tight around my body.',\n",
       " \"I was climbing around a building that was being constructed. There were no stairways, so I climbed up the steel girders. After I got up there to the top, I looked down and couldn't see the ground because of the maze of girders below me. I stood there with my feet on separate beams and wondered how I was going to get down. After a while, a foreman came up and said that if I didn't have anything to do I could go to work. He took me into a small room and gave me a sheaf of papers and told me to start checking off items.\",\n",
       " \"One evening I went down to my friend's house to pay him a visit. When I came in, Richard's mother told me I would find him resting in his bedroom. I walked into his bedroom and was quite surprised to find his younger cousin there and Richard in his pajamas. (He always lies down in his street clothes when he takes a rest, and he never wears pajamas.) When I came in he jumped up grinning and we started to wrestle around the room.\",\n",
       " 'My girlfriend and I were sitting on a couch in her house. Suddenly my girl pulled a gun from my pocket and handed it to me. She begged me to shoot her. I was mortified. I ran to the door but she ran after me. I knew that her only wish was for me to shoot her. I pulled the trigger and then I began to laugh.',\n",
       " 'I dreamed I saw a house whose eaves were burning. I thought this was very strange that only the eaves were burning. As I stood there watching, an old man came up to me and said, \"Don\\'t worry, that house has been burning that way as long as I can remember.\" Then some women came running out of the house crying, \"Call the fire department.\" Just then a fire truck rolled up and the firemen began to put out the fire. I don\\'t remember them using any fire equipment other than the truck, but the fire was soon out and the house showed no signs of damage. The old man disappeared and the women who came out of the house invited me in and said it surely was a good thing I happened to be passing by.',\n",
       " 'I was listening to the radio in my home when a news broadcast came on. It stated that Kay Starr, the singer, had been killed in an auto crash in Hollywood, California. I seemed very shocked at this notice of her death. I turned to another station and the program was a record show. The first piece I heard was by Kay Starr. I turned the radio off.',\n",
       " 'I was sitting on a throne of gold surrounded by beautiful girls. The girls kept pawing me and I kept chasing them away. Suddenly one girl stood up and came close to me. I was surprised by her good looks. She bent down and kissed me. I felt thrilled. I put my arms around her and picked her up. We danced for a while. I was taken by her beauty. She was a most beautiful creature. I went wherever she went. I received a thrill every time she touched me. I wanted her badly. The next, I believe we were both floating in the clouds completely nude. We were pleasantly talking and laughing. We were dancing and singing suddenly, extremely happy. I continually kissed the girl, and she reciprocated. We stood arm in arm rolling on.',\n",
       " 'I was standing on one bank of a river looking at a structure on the other side. The structure was in the general shape of a barn, but was of a light cream color and of a modern design. Suddenly I was on the barn side of the river and was watching a little girl who had swallowed a nail. (Her body and features were that of a small girl, but somehow she seemed to be older.) Her brother was there and was going to use a small suction pump to remove the nail from her stomach. He attached the suction pump on her mouth and played an organ while the pump was working. (I was not conscious of any sounds however.) The little girl fainted (or something similar) and the nail fell to the ground. (We were standing ankle deep in water all this time.) I was shocked when the nail fell into the water onto the ground and I stared at the nail for some time.',\n",
       " \"I dreamed that it was morning and that I was to wake up the other men sleeping on the second floor of my fraternity house. I picked up a dry mop (my roommate is a part-time brush salesman and frequently has such in the room). Grasping it by the mop end, I proceeded to go around waking up all the sleepers in the house. This I did by poking them in the chest with the handle of the mop. The last I came to was my roommate (roommates since last September -- his age 24). Instead of the chest I poked him in the genital area and was surprised to find that the handle penetrated into his body to a depth of several inches. I wiggled the mop handle around to waken him, at which time there appeared several other men who seemed to be quite astonished. The last thing I remember was asking him how in the world it had been possible to make the insertion without injuring him. I can't remember what his answer was.\",\n",
       " \"I was standing in a railroad station. The location of the station was unknown to me, and all I noticed about it was that it was very bare and desolate. There was a great crowd of people in it, but I could not distinguish any of their features. As I stood there, I saw a man in an Army uniform of the first world war. I was puzzled because I could not distinguish his rank. On one sleeve he a had a red major's star, and on the other sleeve he had a gold and black private's stripe. I was looking for someone but could not find anyone due to the large group of soldiers that were boarding the train under the direction of this one soldier described before. As I watched, a soldier came running up to the station and just managed to board the train as it pulled out of the station. The thought struck me that the soldier was a girl that used to live next door to us, but had moved many years ago. I began to chase the train yelling that the last soldier was a girl and did not belong on the train.\",\n",
       " 'A friend (25, m), an unidentified person, and I went to the back door of a nightclub. After descending a flight of stairs in darkness we entered a large room. It seemed that a party was going on, but only a few couples were there. They were dancing near the door which we had come in. On the other side of the room was a raised platform with chairs arranged in a semicircle for a symphony orchestra. A few of the chairs were occupied. My friend began to play classical music on the piano picking out each note slowly. I was surprised because he had never played classics before. At the foot of the piano was a basket filled with uncooked pieces of meat. I began picking up hams and roasts and then putting them back in the basket.',\n",
       " 'I dreamt that I was an MP at Fort Knox. On a Saturday night I tried to go on pass, but an officer stopped me. He told me that I was restricted to my quarters for having unpressed pants. I went to the orderly room and saw John there (he was in my outfit in Japan). I was surprised to see him for he hated the army. We talked about our days in Japan. Then I awoke.',\n",
       " 'I was seated in front of a group of elderly bearded men who sat solemnly like a tribunal. Each of these people had a large cloth bag seemed with a drawstring, on the floor next to him. One at a time they would bring forth and/or take something from their sack and make a speech about it. As I remember, the articles included a book, a hat, a pair of socks, and a pipe. The talks were discussions of the characteristics of each article. The speaker would say a few words, and then his companions would tell him to sit down, and another person would start. This procedure was repeated several times. One of the men kept laughing at everything that was said, and finally his companions told him he must stop or else leave. Then a large French door was down in front of the whole scene, and the dream ended there, as looking at a blank wall.',\n",
       " \"I was in a strange town, living at a strange hotel. It occurred to me that I was at a convention of some sort. I seemed to be floating not walking around. I spoke to people easily and casually but do not remember any of the people and it occurred to me at the time that I did not know them. I kept looking for clothing stores. I had a desire to buy some clothes. I kept looking but couldn't find anything but drug stores, jewelry stores and fruit stores. I became frustrated and started back to my hotel. When I got to my hotel I noticed that on both sides of it was located a jewelry store.\",\n",
       " 'I was in a card game (poker) with some of my high school buddies and I was winning a lot. A clock strikes in the distance and I say I have to leave. After a brief argument I leave. When I am home I count my winnings, and I am surprised that I have won 1/16 of a million dollars.',\n",
       " \"While walking to class I met a close friend with whom I often go out on double dates. Upon meeting Phil, my friend, he told me that he had to make a stop for about 15 minutes during our date that Saturday. He wanted to know if it was alright with me, because I was driving that Saturday. I was very confused because I thought Phil had previously told me that he couldn't go with us that Saturday, so I made arrangements to go with another couple.\",\n",
       " 'I had been standing in my bedroom all day watching the peculiar actions of a blimp. It would fly back and forth over the house and disappear for a few minutes. It remained rather high in the air until the afternoon. Then gray clouds began to form in the horizon and the blimp came lower and lower. I put on my pea jacket and reached the backyard just in time to see the silvery blimp land in a field that adjoins our home. I was absolutely amazed. Why should a blimp land here? A small door in the gondola opened and two crew members climbed out. They wore navy uniforms. Suddenly I noticed one of my fraternity brothers (who is a clown and not a very good student) running over to the man who appeared to be in charge. My fraternity brother assured him that it was permissible to moor the blimp in the field for as long as he desired. The captain of the blimp said he must leave soon. My fraternity brother was disappointed for he wanted to use the blimp for an air force demonstration at school.',\n",
       " 'I had found a television set somewhere in my home. The chief concern of the dream was the television set. It was different from any set I have seen, in that it worked with a switch on the end of a cord, and the screen part was in a separate unit, detachable from the rest of the set. I remember being quite surprised at finding it. I played with the set for a few minutes and then walked away from it, whereupon I awoke.',\n",
       " 'I dreamt that one of my friends and I were walking down a strange street at night. We walked for a while and then went into a bar. We had a few beers and then started to flirt with two blonds. Then I was playing softball in an empty lot near my home. I batted a long drive into left field and was dismayed when the fielder caught the ball.',\n",
       " 'I was with a girl who may have been my wife. We were wandering around in a triangular plot of land bordered by railroad tracks at two sides. I was looking over the land to determine its possibilities for shooting (possibly hunting). I was very doubtful about my reasons for doing this or why I had chosen this plot to look over. Then I started to discuss my plans with the owner of the land who was a railroad official. I remember the plot of land as being located near the East Cleveland Station where I had sometimes played when I was a boy.',\n",
       " \"It started in the afternoon of a very important day to me. There was a big formal dance going on this night. I went to the garage to get the car and when I tried to start the car nothing happened. I looked under the hood and the motor was missing. What a surprise. I called my uncle and told him what happened -- 'someone has stolen the motor out of the car.' We looked around the garage for clues and found the motor in a vacant lot next to the garage. It had been taken apart and scattered all around. It took us two days to put it together.\",\n",
       " \"Was in a hotel with seven floors. My suite was on the seventh. Can't remember the room itself, but I left to go down to the lobby. Used the stairs, took the wrong door at the bottom and ended up outside. Walked around and went back in entering the lobby first. I think, because of my attire, I had to make a fast exit, so headed for the elevator. Got in and the operator talked and talked. We kept going up and up, past the seventh floor and it puzzled me to feel as if we were still moving up having passed the top floor. The door opened eventually and the operator and a colleague waiting on the roof tried to roll me. I said I only had two bucks on me. To show him I pulled out a bill which was a five. That startled me and both of them pounced on me. With this I awakened.\",\n",
       " 'I was lying on a beach next to the ocean with the sound of the waves in my ears. The sun was bright but pleasantly warm. I closed my eyes to keep out its brightness and when I opened them again the sun had set and the world was bathed in twilight. Suddenly the waves parted and a girl strode toward me. I looked around and to my surprise found we were alone. Not speaking she lay down by my side and we had intercourse.']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# idx_end = int(len(pstv_rprts)*.7)\n",
    "# len(pstv_rprts), idx_end, len(pstv_rprts[:idx_end]), len(pstv_rprts[idx_end:])\n",
    "pstv_rprts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57f36c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "da4a3bc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 176.11it/s]\n"
     ]
    }
   ],
   "source": [
    "idx_end = int(len(pstv_rprts)* train_ratio)\n",
    "\n",
    "for cllctn in tqdm(set(dream_records[\"collection\"])):\n",
    "    for emtn in set(dream_records[dream_records[\"# Emotions\"].isin([1])][\"Emotions\"]):\n",
    "        \n",
    "        # list of reports with specific collection-emotion combination\n",
    "        pstv_rprts = dream_records[\n",
    "            dream_records[\"collection\"].isin([cllctn]) & \n",
    "            dream_records[\"Emotions\"].isin([emtn])\n",
    "        ][\"report\"].to_list()\n",
    "        \n",
    "        # sample reports with from same collection  butdifferent emotion\n",
    "        ngtv_rprts = dream_records[\n",
    "            dream_records[\"collection\"].isin([cllctn]) & \n",
    "            ~dream_records[\"Emotions\"].isin([emtn])\n",
    "        ].sample(len(pstv_rprts))[\"report\"].to_list()\n",
    "        \n",
    "        random.shuffle(pstv_rprts), random.shuffle(ngtv_rprts) \n",
    "        \n",
    "        pst_Trn = list(zip(pstv_rprts[:idx_end], [1]  * idx_end))\n",
    "        ngt_Trn = list(zip(ngtv_rprts[:idx_end], [0]  * idx_end))\n",
    "\n",
    "        pst_tst = list(zip(pstv_rprts[idx_end:], [1]  * idx_end))\n",
    "        ngt_tst = list(zip(ngtv_rprts[idx_end:], [0]  * idx_end))\n",
    "        \n",
    "#         X_train, X_test = pstv_rprts[:idx_end], pstv_rprts[idx_end:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046b20c8",
   "metadata": {},
   "source": [
    "### Supervised Learning<a id='train'></a>\n",
    "#### Frozen Model + Classification Layer<a id='cls'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "412d2dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name  = \"bert-large-cased\"\n",
    "max_length  = 512\n",
    "device      = \"cuda\"\n",
    "epochs      = 5\n",
    "batch_size  = 16\n",
    "train_ratio = .7\n",
    "froze_model_layer = True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180cec11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the training / test data\n",
    "train_encodings = tokenizer(\n",
    "    list(X_train), \n",
    "    truncation=True, \n",
    "    padding=True, \n",
    "    max_length=max_length\n",
    ")\n",
    "\n",
    "test_encodings = tokenizer(\n",
    "    list(X_test), \n",
    "    truncation=True, \n",
    "    padding=True, \n",
    "    max_length=max_length\n",
    ")\n",
    "\n",
    "# convert our tokenized data into a torch Dataset\n",
    "train_dataset = HF_Dataset(train_encodings, y_train)\n",
    "test_dataset  = HF_Dataset(test_encodings, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d2f11a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-large-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# load the tokenizer\n",
    "tokenizer       = BertTokenizerFast.from_pretrained(model_name, do_lower_case=True)\n",
    "tokenizer_vocab = list(tokenizer.get_vocab().keys())\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(model_name, num_labels=2).to(device)\n",
    "\n",
    "# Froze the weight of model aside of the classifier\n",
    "if froze_model_layer:\n",
    "    for name, param in model.named_parameters():\n",
    "        if \"classifier\" not in name:\n",
    "            param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a6fbf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',                  # output directory\n",
    "    num_train_epochs=epochs,                 # total number of training epochs\n",
    "    per_device_train_batch_size=batch_size,  # batch size per device during training\n",
    "    per_device_eval_batch_size=batch_size,   # batch size for evaluation\n",
    "    warmup_steps=100,                     # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,   \n",
    "    \n",
    "    # strength of weight decay\n",
    "    logging_dir='./logs',            # directory for storing logs\n",
    "    load_best_model_at_end=False,    # load the best model when finished training (default\n",
    "                                     # metric is loss)\n",
    "    \n",
    "    # but you can specify `metric_for_best_model` argument to change \n",
    "    # to accuracy or other metric\n",
    "    logging_steps=400,               # log & save weights each logging_steps\n",
    "    evaluation_strategy=\"no\",        # evaluate each `logging_steps`\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model = model,                         # the instantiated Transformers model to be trained\n",
    "    args  = training_args,                 # training arguments, defined above\n",
    "    train_dataset = train_dataset,         # training dataset\n",
    "    eval_dataset  = test_dataset,          # evaluation dataset\n",
    "    compute_metrics = compute_metrics,     # the callback that computes metrics of interest\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eccad80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model (sanity check befor training) \n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5dc039",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df65d69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "715ef6f9",
   "metadata": {},
   "source": [
    "#### Frozen Model + Logistic regression (sigmoid layer)<a id='sigmoid'></a>\n",
    "We will use the embeddin gs extracted from previous notebook as input \"frozen\" vectors â€“ i.e. computational encodings for each report.\n",
    "\n",
    "Then, a logistic regression model is trained for each label to predict the extent to which su label is present in a given encoding. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb27a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('BERT-Large-Cased_dream_records.npy', 'rb') as f:\n",
    "    T_encoding = np.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c772f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression(torch.nn.Module):\n",
    "    \n",
    "    \"\"\"A trainable logistic regression model built from pytorch.\n",
    "    \n",
    "    Initilaisation Args:\n",
    "        input_dim: int, number of dimensions of the input (vector features).\n",
    "        output_dim: int, number of desired classes to classify (number of label's feature).\n",
    "    \n",
    "    Forward args: (training-loop function, i.e. forward step of the model)\n",
    "        x: tensor having input_dim, batch_size shape.\n",
    "    \n",
    "    Output:\n",
    "        tensor with gradient for backward pass (i.e. back-propagation).\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.linear = torch.nn.Linear(input_dim, output_dim)\n",
    "    def forward(self, x):\n",
    "        outputs = torch.sigmoid(self.linear(x))\n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2e1243ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get training instances and labels\n",
    "X_train, y_train = torch.Tensor(T_encoding), torch.Tensor(angr[:debug])\n",
    "train_dataset = list(zip(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9ab0f278",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=64, \n",
    "                                           shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9a6625eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the dimension of the encoding\n",
    "embedding_dim = T_encoding[0].shape[0]\n",
    "\n",
    "# pyTorch notation, we need to define a model and a loss funtion to compute the score \n",
    "logti_angr = LogisticRegression(embedding_dim, 1) # one logit per feature/emotion\n",
    "optimizer  = torch.optim.SGD(logti_angr.parameters(), lr=.001)\n",
    "criterion  = nn.MSELoss()  # loss f(), in this case mean square error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "af332da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "logti_angr = logti_angr.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "11c18616",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in pyTorch, we compute the loss at each step, with 1 or more batches (i.e., inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d7875ef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 68.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0 Loss: 0.0233\n",
      "Iteration: 1 Loss: 0.0187\n",
      "Iteration: 2 Loss: 0.0160\n",
      "Iteration: 3 Loss: 0.0151\n",
      "Iteration: 4 Loss: 0.0161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "it, epochs = 0, 5\n",
    "for epoch in tqdm(range(int(epochs))):\n",
    "    for i, (seq, score) in enumerate(train_loader):\n",
    "        \n",
    "        seq = seq.to('cuda')\n",
    "        score = score.to('cuda')\n",
    "        optimizer.zero_grad()\n",
    "        outputs = logti_angr(seq)\n",
    "        loss = criterion(outputs, score)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "#         it+=1\n",
    "#         if it%500==0:\n",
    "#             # calculate Accuracy\n",
    "#             correct = 0\n",
    "#             total = 0\n",
    "#             for images, labels in test_loader:\n",
    "#                 images = Variable(images.view(-1, 28*28))\n",
    "#                 outputs = model(images)\n",
    "#                 _, predicted = torch.max(outputs.data, 1)\n",
    "#                 total+= labels.size(0)\n",
    "#                 # for gpu, bring the predicted and labels back to cpu fro python operations to work\n",
    "#                 correct+= (predicted == labels).sum()\n",
    "#             accuracy = 100 * correct/total\n",
    "    print(\"Iteration: {} Loss: {:.4f}\".format(epoch, loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed3cab6",
   "metadata": {},
   "source": [
    "#### Frozen Model + Feed-Forward Neural Network (FFNN)<a id='ffnn'></a>\n",
    "We will use the embeddin gs extracted from previous notebook as input \"frozen\" vectors â€“ i.e. computational encodings for each report.\n",
    "\n",
    "Then, a one-hidden-layer feed forward architecture will classify the input, and predict the score of the given label, in terms of \"output cell\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8517b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FF_Network(nn.Module):\n",
    "    \n",
    "    \"\"\"A trainable Feedâ€“Forwad model built from pytorch.\n",
    "\n",
    "    Initilaisation Args:\n",
    "        input_dim: int, number of dimensions of the input (vector features).\n",
    "        hidden_dimensions: int, number of features to reduce the input in\n",
    "        output_classe: int, number of desired classes to classify (number of label's feature).\n",
    "\n",
    "    Forward args: (training-loop function, i.e. forward step of the model)\n",
    "        x: tensor having input_dim, batch_size shape.\n",
    "\n",
    "    Output:\n",
    "        tensor with gradient for backward pass (i.e. back-propagation).\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim, hidden_dimensions, output_classes):\n",
    "        super(FF_Network, self).__init__()\n",
    "    \n",
    "        # Inputs to hidden layer linear transformation\n",
    "        self.hidden = nn.Linear(input_dim, hidden_dimensions)\n",
    "        # Output layer, 10 units - one for each digit\n",
    "        self.output = nn.Linear(hidden_dimensions, output_classes)\n",
    "        \n",
    "        # Define sigmoid activation and softmax output \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Pass the input tensor through each of our operations\n",
    "        x = self.hidden(x)\n",
    "        x = self.sigmoid(x)\n",
    "        x = self.output(x)\n",
    "        x = self.softmax(x)\n",
    "        \n",
    "        return x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
