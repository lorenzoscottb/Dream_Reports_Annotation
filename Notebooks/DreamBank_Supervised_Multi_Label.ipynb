{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92dd8fa2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Nov  9 16:07:54 2022       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 515.43.04    Driver Version: 515.43.04    CUDA Version: 11.7     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:03:00.0 Off |                  N/A |\r\n",
      "| 33%   58C    P2   132W / 350W |   4215MiB / 24576MiB |     28%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   1  NVIDIA GeForce ...  Off  | 00000000:04:00.0 Off |                  N/A |\r\n",
      "| 30%   23C    P8     4W / 350W |      2MiB / 24576MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   2  NVIDIA GeForce ...  Off  | 00000000:43:00.0 Off |                  N/A |\r\n",
      "| 30%   24C    P8     5W / 350W |      2MiB / 24576MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   3  NVIDIA GeForce ...  Off  | 00000000:44:00.0 Off |                  N/A |\r\n",
      "| 30%   25C    P8     2W / 350W |      2MiB / 24576MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   4  NVIDIA GeForce ...  Off  | 00000000:87:00.0 Off |                  N/A |\r\n",
      "| 30%   21C    P8    13W / 350W |   9765MiB / 24576MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   5  NVIDIA GeForce ...  Off  | 00000000:88:00.0 Off |                  N/A |\r\n",
      "| 30%   24C    P8     6W / 350W |      2MiB / 24576MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   6  NVIDIA GeForce ...  Off  | 00000000:C3:00.0 Off |                  N/A |\r\n",
      "| 30%   24C    P8     1W / 350W |      2MiB / 24576MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   7  NVIDIA GeForce ...  Off  | 00000000:C4:00.0 Off |                  N/A |\r\n",
      "| 30%   24C    P8     5W / 350W |      2MiB / 24576MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0   N/A  N/A   1102004      C   ...elf-explain/bin/python3.9     4213MiB |\r\n",
      "|    4   N/A  N/A   1083501      C   ...3/envs/cedr/bin/python3.9     9763MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "! nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82ba9aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, random\n",
    "\n",
    "# Makes sure the script has acess to one GPU\n",
    "cuda_device = 5\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(cuda_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "palestinian-clear",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Basic\" py library\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# visualisation\n",
    "from matplotlib import pyplot as plt # basic visualisation in py\n",
    "import seaborn as sns # great to interact with dataframes\n",
    "from tqdm import tqdm  # generats progress bar to controll steps\n",
    "\n",
    "import torch # Pytorch, Meta's library for ML\n",
    "import torch.nn as nn # torch module for neural networks \n",
    "\n",
    "import transformers # HuggingFace library to use pretrained models\n",
    "from transformers import BertTokenizerFast, BertForSequenceClassification\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from torch.utils.data import TensorDataset, random_split, SubsetRandomSampler, ConcatDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bdaa463",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed: int, set_random=True):\n",
    "    \"\"\"Helper function for reproducible behavior to set the seed in ``random``, \n",
    "        ``numpy``, ``torch`` and/or ``tf`` (if installed).\n",
    "\n",
    "    Args:\n",
    "        seed (:obj:`int`): The seed to set.\n",
    "    \"\"\"\n",
    "    from transformers.file_utils import is_tf_available, is_torch_available, is_torch_tpu_available\n",
    "    \n",
    "    if set_random:\n",
    "        random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    if is_torch_available():\n",
    "        torch.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        # ^^ safe to call this function even if cuda is not available\n",
    "    if is_tf_available():\n",
    "        import tensorflow as tf\n",
    "\n",
    "        tf.random.set_seed(seed)\n",
    "    \n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd0722f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set visual style\n",
    "sns.set(\"talk\")\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "#  set the rabdom seed \n",
    "seed = 31\n",
    "set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "812d80dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "\n",
    "    def __init__(self, dataframe, tokenizer, max_len=512):\n",
    "        self.tokenizer = tokenizer                      # the Tokenizer model\n",
    "        self.data      = dataframe                      # the full dataset\n",
    "        self.report    = dataframe.report               # the text data (i.e., the reports)\n",
    "        self.targets   = self.data.Report_as_Multilabel # labels' list to classify\n",
    "        self.max_len   = max_length                     # max length fro truncation\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.report)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        report = str(self.report[index])\n",
    "        report = \" \".join(report.split())\n",
    "\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            report,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            pad_to_max_length=True,\n",
    "            return_token_type_ids=True\n",
    "        )\n",
    "        ids = inputs['input_ids']\n",
    "        mask = inputs['attention_mask']\n",
    "        token_type_ids = inputs[\"token_type_ids\"]\n",
    "\n",
    "        return {\n",
    "            'ids': torch.tensor(ids, dtype=torch.long),\n",
    "            'mask': torch.tensor(mask, dtype=torch.long),\n",
    "            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
    "            'targets': torch.tensor(self.targets[index], dtype=torch.float)\n",
    "        }\n",
    "    \n",
    "# Creating the dataset and dataloader for the neural network\n",
    "def get_Fold(k_seed):\n",
    "    train_size = 0.8\n",
    "    train_dataset = final_df_dataset.sample(frac=train_size, random_state=k_seed)\n",
    "    test_dataset  = final_df_dataset.drop(train_dataset.index).reset_index(drop=True)\n",
    "    train_dataset = train_dataset.reset_index(drop=True)\n",
    "\n",
    "    training_set = CustomDataset(train_dataset, tokenizer, max_length)\n",
    "    testing_set  = CustomDataset(test_dataset, tokenizer, max_length)\n",
    "\n",
    "    train_params = {\n",
    "        'batch_size': train_batch_size,\n",
    "        'shuffle': True,\n",
    "        'num_workers': 0\n",
    "    }\n",
    "\n",
    "    test_params = {\n",
    "        'batch_size': valid_batch_size,\n",
    "        'shuffle': True,\n",
    "        'num_workers': 0\n",
    "    }\n",
    "\n",
    "    training_loader = DataLoader(training_set, **train_params)\n",
    "    testing_loader  = DataLoader(testing_set, **test_params)\n",
    "    \n",
    "    return training_loader, testing_loader\n",
    "\n",
    "# Creating the customized model, by adding a drop out and a dense layer on top of \n",
    "# the BERT (or any other) model, to get the final output. \n",
    "class BERTClass(torch.nn.Module):\n",
    "    def __init__(self, model_name, n_classes, freeze_BERT=False, layer=-1, idx=0):\n",
    "        super(BERTClass, self).__init__()\n",
    "        self.l1 = transformers.BertModel.from_pretrained(model_name)\n",
    "        self.l2 = torch.nn.Dropout(0.3)\n",
    "        self.l3 = torch.nn.Linear(1024, n_classes)\n",
    "        self.layer = layer\n",
    "        self.idx   = idx  \n",
    "        # Froze the weight of model aside of the classifier\n",
    "        if froze_model_layer:\n",
    "            print(\"Freezing the layer of BERT model\")\n",
    "            for name, param in self.l1.named_parameters():\n",
    "                if \"classifier\" not in name:\n",
    "                    param.requires_grad = False\n",
    "                    \n",
    "    def forward(self, ids, mask, token_type_ids):\n",
    "        output_1 = self.l1(ids, attention_mask = mask, token_type_ids = token_type_ids)\n",
    "        output_1 = output_1.last_hidden_state[:, -1, :]\n",
    "        output_2 = self.l2(output_1)\n",
    "        output   = self.l3(output_2)\n",
    "        return output\n",
    "\n",
    "# Loss function \n",
    "def loss_fn(outputs, targets):\n",
    "    return torch.nn.BCEWithLogitsLoss()(outputs, targets)\n",
    "\n",
    "# Training regime\n",
    "def train(epoch, model, training_loader, optimizer, return_losses=False):\n",
    "    Losses = []\n",
    "    model.train()\n",
    "    for _, data in enumerate(training_loader, 0):\n",
    "        ids = data['ids'].to(device, dtype = torch.long)\n",
    "        mask = data['mask'].to(device, dtype = torch.long)\n",
    "        token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
    "        targets = data['targets'].to(device, dtype = torch.float)\n",
    "\n",
    "        outputs = model(ids, mask, token_type_ids)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        if _%5000==0:\n",
    "            print(f'Epoch: {epoch}, Loss:  {loss.item()}')\n",
    "            Losses.append(loss.item())\n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    if return_losses:\n",
    "        return Losses\n",
    "    \n",
    "# Validate (test) the model\n",
    "def validation(model, testing_loader):\n",
    "    model.eval()\n",
    "    fin_targets=[]\n",
    "    fin_outputs=[]\n",
    "    with torch.no_grad():\n",
    "        for _, data in enumerate(testing_loader, 0):\n",
    "            ids = data['ids'].to(device, dtype = torch.long)\n",
    "            mask = data['mask'].to(device, dtype = torch.long)\n",
    "            token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
    "            targets = data['targets'].to(device, dtype = torch.float)\n",
    "            outputs = model(ids, mask, token_type_ids)\n",
    "            fin_targets.extend(targets.cpu().detach().numpy().tolist())\n",
    "            fin_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n",
    "    return fin_outputs, fin_targets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "favorite-prize",
   "metadata": {},
   "source": [
    "# Table of Content\n",
    "\n",
    "click on the titles to reach the described sections\n",
    "\n",
    "---------\n",
    "[Loading Data](#intro)\n",
    "\n",
    "[Dataset and Model Setup](#setup)\n",
    "\n",
    "[Training and Evaluation](#train_eval)\n",
    "\n",
    "[Analysis](#analysis)\n",
    "\n",
    "[K-Fold Experiment](#kfold)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "weird-illness",
   "metadata": {},
   "source": [
    "## Loading data<a id='intro'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98529ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset in CSV\n",
    "dream_records = pd.read_csv(\n",
    "    \"Reports_DreamerEmotions_PCACho_tsneCho_KMCluster2_KMCluster6_2WSA_6WSA.csv\"\n",
    ")\n",
    "\n",
    "Coding_emotions = {\n",
    "    \"AN\": \"Anger\",\n",
    "    \"AP\": \"Apprehension\",\n",
    "    \"SD\": \"Sadness\",\n",
    "    \"CO\": \"Confusion\",\n",
    "    \"HA\": \"Happiness\",\n",
    "    \n",
    "    \"Missing\": \"Missing\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037d8ed9",
   "metadata": {},
   "source": [
    "Convert each set of labels/Emotion is a list signaling the prsence/absence of each emotion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d8f9c47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 1845/1845 [00:00<00:00, 703755.08it/s]\n"
     ]
    }
   ],
   "source": [
    "emotions_list = list(Coding_emotions.keys())\n",
    "emotions_list.remove(\"Missing\")\n",
    "\n",
    "report_as_multi_label = []\n",
    "for rprt_emtn_lst in tqdm(dream_records[\"Emotions\"]):\n",
    "    lcl_report_as_multi_label = []\n",
    "    for emotion_acronim in emotions_list:\n",
    "        if emotion_acronim in rprt_emtn_lst:\n",
    "            lcl_report_as_multi_label.append(1)\n",
    "        else:\n",
    "            lcl_report_as_multi_label.append(0)\n",
    "    report_as_multi_label.append(lcl_report_as_multi_label)\n",
    "\n",
    "dream_records[\"Report_as_Multilabel\"] = report_as_multi_label\n",
    "\n",
    "# final_df_dataset = dream_records\n",
    "\n",
    "final_df_dataset = dream_records[~dream_records[\"# Emotions\"].isin([0])].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3b721ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['gender', 'age', 'type', 'collection', 'id', 'time', 'date', 'number',\n",
       "       'report', '# words', 'Emotions', '# Emotions', 'TSNE_x', 'TSNE_y',\n",
       "       'PCA_x', 'PCA_y', 'Kmean_Cluster_6', 'Kmean Cluster_2', '2W_SA_label',\n",
       "       '2W_SA_score', '6W_SA_dict', 'Report_as_Multilabel'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df_dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc133132",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df_dataset = final_df_dataset[[\"report\", \"Report_as_Multilabel\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee413b2",
   "metadata": {},
   "source": [
    "## Dataset and Model Setup<a id='setup'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "397e094e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining model's specifications \n",
    "model_name        = \"bert-large-cased\"\n",
    "max_length        = 512\n",
    "device            = \"cuda\"\n",
    "epochs            = 5\n",
    "train_batch_size  = 8 # always use power of 2!\n",
    "valid_batch_size  = 4\n",
    "train_ratio       = .7\n",
    "learning_rate     = 1e-05\n",
    "froze_model_layer = False \n",
    "\n",
    "# Tokenizer defined first to tokenize the inputs in the Dataset object\n",
    "tokenizer = BertTokenizerFast.from_pretrained(model_name, do_lower_case=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c7277de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FULL Dataset:  (778, 2)\n",
      "TRAIN Dataset: (622, 2)\n",
      "TEST Dataset:  (156, 2)\n"
     ]
    }
   ],
   "source": [
    "# Creating the dataset and dataloader for the neural network\n",
    "\n",
    "train_size = 0.8\n",
    "train_dataset = final_df_dataset.sample(frac=train_size, random_state=seed)\n",
    "test_dataset  = final_df_dataset.drop(train_dataset.index).reset_index(drop=True)\n",
    "train_dataset = train_dataset.reset_index(drop=True)\n",
    "\n",
    "print(\"FULL Dataset:  {}\".format(final_df_dataset.shape))\n",
    "print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n",
    "print(\"TEST Dataset:  {}\".format(test_dataset.shape))\n",
    "\n",
    "training_set = CustomDataset(train_dataset, tokenizer, max_length)\n",
    "testing_set  = CustomDataset(test_dataset, tokenizer, max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c76d4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_params = {\n",
    "    'batch_size': train_batch_size,\n",
    "    'shuffle': True,\n",
    "    'num_workers': 0\n",
    "}\n",
    "\n",
    "test_params = {\n",
    "    'batch_size': valid_batch_size,\n",
    "    'shuffle': True,\n",
    "    'num_workers': 0\n",
    "}\n",
    "\n",
    "training_loader = DataLoader(training_set, **train_params)\n",
    "testing_loader  = DataLoader(testing_set, **test_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5df33800",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model_tuned = BERTClass(\n",
    "    model_name=model_name, \n",
    "    n_classes=len(emotions_list), \n",
    "    freeze_BERT=False\n",
    ")\n",
    "\n",
    "model_tuned.to(device)\n",
    "\n",
    "optimizer_tuned = torch.optim.Adam(\n",
    "    params=model_tuned.parameters(), \n",
    "    lr=learning_rate\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd2fa5f",
   "metadata": {},
   "source": [
    "## Training and Evaluation<a id='train_eval'></a>\n",
    "Training a model on a single split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e7d41af9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/srv/galene1/lb540/miniconda/envs/main_39/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2323: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss:  0.7251710295677185\n",
      "Epoch: 1, Loss:  0.5469126105308533\n",
      "Epoch: 2, Loss:  0.5461908578872681\n",
      "Epoch: 3, Loss:  0.4007751941680908\n",
      "Epoch: 4, Loss:  0.36560940742492676\n"
     ]
    }
   ],
   "source": [
    "for ep in range(epochs):\n",
    "    train(ep, model_tuned, training_loader, optimizer_tuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5a039e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs, targets = validation(model_tuned, testing_loader)\n",
    "outputs = np.array(outputs) >= 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6aa176d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AN</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.83</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP</th>\n",
       "      <td>0.83</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.74</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.24</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CO</th>\n",
       "      <td>0.67</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.54</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HA</th>\n",
       "      <td>0.89</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.67</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>micro avg</th>\n",
       "      <td>0.82</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.67</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.60</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.64</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>samples avg</th>\n",
       "      <td>0.60</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.59</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision  recall  f1-score  support\n",
       "AN                 0.85    0.81      0.83       27\n",
       "AP                 0.83    0.66      0.74       68\n",
       "SD                 1.00    0.14      0.24       22\n",
       "CO                 0.67    0.45      0.54       31\n",
       "HA                 0.89    0.53      0.67       32\n",
       "micro avg          0.82    0.56      0.67      180\n",
       "macro avg          0.85    0.52      0.60      180\n",
       "weighted avg       0.84    0.56      0.64      180\n",
       "samples avg        0.60    0.59      0.59      180"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(\n",
    "    metrics.classification_report(\n",
    "        targets,\n",
    "        outputs,\n",
    "        target_names=emotions_list,\n",
    "        zero_division=0,\n",
    "        output_dict=True,\n",
    "    ), \n",
    "    orient='index',\n",
    ").round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0074669",
   "metadata": {},
   "source": [
    "## Analysis<a id='analysis'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b03768b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x216 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "emotions_CM = metrics.multilabel_confusion_matrix(\n",
    "    targets,\n",
    "    outputs,\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(15, 3))\n",
    "for cnt, cm in enumerate(emotions_CM): \n",
    "    \n",
    "    plt.subplot(1,5,cnt+1) \n",
    "    g = sns.heatmap(cm, cmap=\"crest\", cbar=False, annot=True)\n",
    "    plt.title(\"Emotion: {}\".format(emotions_list[cnt]))\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    if cnt == 0:\n",
    "        plt.ylabel(\"True\")\n",
    "    else:\n",
    "        g.set_yticklabels([\"\", \"\"])\n",
    "        \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2b7c1990",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AN', 'AP', 'SD', 'CO', 'HA']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotions_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "25735e0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15, 7))\n",
    "for cnt, [name, data] in enumerate({\"True\":targets, \"Predicted\":outputs}.items()): \n",
    "    \n",
    "    rot_data = np.rot90(data)\n",
    "    _bar = True if cnt != 0 else False\n",
    "    plt.subplot(2,1,cnt+1)\n",
    "    g = sns.heatmap(\n",
    "            rot_data, \n",
    "            cmap=\"crest\",\n",
    "            linewidth=.8,\n",
    "            xticklabels=False, \n",
    "            yticklabels=list(reversed(emotions_list)),\n",
    "            cbar=False,\n",
    "    )\n",
    "    g.set_yticklabels(g.get_yticklabels(), rotation=30)        \n",
    "    plt.title(\"{}\".format(name))\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d04a524",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1b9954c3",
   "metadata": {},
   "source": [
    "## K-Fold Experiment<a id='kfold'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "30b5536c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining model's specifications \n",
    "model_name        = \"bert-large-cased\"\n",
    "max_length        = 512\n",
    "device            = \"cuda\"\n",
    "epochs            = 5\n",
    "train_batch_size  = 8 # always use power of 2!\n",
    "valid_batch_size  = 4\n",
    "train_ratio       = .7\n",
    "learning_rate     = 1e-05\n",
    "froze_model_layer = False \n",
    "\n",
    "# Tokenizer defined first to tokenize the inputs in the Dataset object\n",
    "tokenizer = BertTokenizerFast.from_pretrained(model_name, do_lower_case=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "35cc123d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/srv/galene1/lb540/miniconda/envs/main_39/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2323: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss:  0.7020222544670105\n",
      "Epoch: 1, Loss:  0.6622578501701355\n",
      "Epoch: 2, Loss:  0.5281147956848145\n",
      "Epoch: 3, Loss:  0.4457736611366272\n",
      "Epoch: 4, Loss:  0.21643920242786407\n",
      "Testing the Model\n",
      "F1 samples avg.: 0.86\n",
      "Fold 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/srv/galene1/lb540/miniconda/envs/main_39/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2323: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss:  0.7276678085327148\n",
      "Epoch: 1, Loss:  0.6097238659858704\n",
      "Epoch: 2, Loss:  0.46570754051208496\n",
      "Epoch: 3, Loss:  0.19502349197864532\n",
      "Epoch: 4, Loss:  0.1153481975197792\n",
      "Testing the Model\n",
      "F1 samples avg.: 0.85\n",
      "Fold 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/srv/galene1/lb540/miniconda/envs/main_39/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2323: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss:  0.7322759032249451\n",
      "Epoch: 1, Loss:  0.6032800674438477\n",
      "Epoch: 2, Loss:  0.5944746732711792\n",
      "Epoch: 3, Loss:  0.4759902060031891\n",
      "Epoch: 4, Loss:  0.2677536606788635\n",
      "Testing the Model\n",
      "F1 samples avg.: 0.78\n",
      "Fold 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/srv/galene1/lb540/miniconda/envs/main_39/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2323: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss:  0.7410435080528259\n",
      "Epoch: 1, Loss:  0.536763072013855\n",
      "Epoch: 2, Loss:  0.32944560050964355\n",
      "Epoch: 3, Loss:  0.2707534730434418\n",
      "Epoch: 4, Loss:  0.14953969419002533\n",
      "Testing the Model\n",
      "F1 samples avg.: 0.8\n",
      "Fold 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/srv/galene1/lb540/miniconda/envs/main_39/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2323: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss:  0.7099923491477966\n",
      "Epoch: 1, Loss:  0.502336859703064\n",
      "Epoch: 2, Loss:  0.6127772331237793\n",
      "Epoch: 3, Loss:  0.3498329222202301\n",
      "Epoch: 4, Loss:  0.37649670243263245\n",
      "Testing the Model\n",
      "F1 samples avg.: 0.69\n"
     ]
    }
   ],
   "source": [
    "SCORES, LOSSES = [], []\n",
    "for fold in range(5):\n",
    "\n",
    "    print('Fold {}'.format(fold + 1))\n",
    "    rand_int = random.randint(0, 10000)\n",
    "    train_loader, testing_loader = get_Fold(rand_int)\n",
    "\n",
    "    # makes sure the seed for model init is the same\n",
    "    set_seed(seed, set_random=False) \n",
    "    \n",
    "    # Set Model and Optmizer (for each fold)\n",
    "    model_tuned = BERTClass(\n",
    "        model_name=model_name, \n",
    "        n_classes=len(emotions_list), \n",
    "        freeze_BERT=False\n",
    "    )\n",
    "\n",
    "    optimizer_tuned = torch.optim.Adam(\n",
    "    params=model_tuned.parameters(), \n",
    "    lr=learning_rate\n",
    "    ) \n",
    "    \n",
    "    model_tuned.to(device)\n",
    "    \n",
    "    #Train and test the model\n",
    "    for ep in range(5):\n",
    "        train_losses = train(\n",
    "            ep, \n",
    "            model_tuned, \n",
    "            train_loader, \n",
    "            optimizer_tuned, \n",
    "            return_losses=True,\n",
    "        )\n",
    "    LOSSES.append(train_losses)\n",
    "    \n",
    "    print(\"Testing the Model\")\n",
    "    outputs, targets = validation(model_tuned, testing_loader)\n",
    "    outputs = np.array(outputs) >= 0.5    \n",
    "    \n",
    "    model_tuned.to(\"cpu\")\n",
    "    del model_tuned # send the model to cpu and delete\n",
    "    \n",
    "    # Compute and print results\n",
    "    results_df = pd.DataFrame.from_dict(\n",
    "        metrics.classification_report(\n",
    "            targets,\n",
    "            outputs,\n",
    "            target_names=emotions_list,\n",
    "            zero_division=0,\n",
    "            output_dict=True,\n",
    "        ), \n",
    "        orient='index',\n",
    "    ).round(2)\n",
    "    \n",
    "    f1_samp_av = results_df.at[\"samples avg\", \"f1-score\"]\n",
    "    print(\"F1 samples avg.: {}\".format(f1_samp_av), end = \"\\n\")\n",
    "    SCORES.append(f1_samp_av)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "54467a9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean F1 samples avg.:80 ± 6.09\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean F1 samples avg.:{:.0f} ± {:.2f}\".format(100*np.mean(SCORES), 100*np.std(SCORES)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6141bb43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
